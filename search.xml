<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>集群搭建</title>
      <link href="posts/56e0c1a5/"/>
      <url>posts/56e0c1a5/</url>
      
        <content type="html"><![CDATA[<h1 id="集群搭建"><a class="markdownIt-Anchor" href="#集群搭建"></a> 集群搭建</h1><h1 id="集群搭建-2"><a class="markdownIt-Anchor" href="#集群搭建-2"></a> <strong>集群搭建：</strong></h1><h3 id="1创建atguigu用户"><a class="markdownIt-Anchor" href="#1创建atguigu用户"></a> <strong>1，创建atguigu用户</strong></h3><p><code>useradd atguigu</code></p><p><code>passwd atguigu</code></p><h3 id="2设置hostname"><a class="markdownIt-Anchor" href="#2设置hostname"></a> <strong>2，设置hostname</strong></h3><p><code>hostnamectl --static set-hostname hadoop102</code></p><h3 id="3关闭防火墙"><a class="markdownIt-Anchor" href="#3关闭防火墙"></a> <strong>3，关闭防火墙</strong></h3><p><code>systemctl stop firewalld</code></p><p><code>systemctl disable firewalld</code></p><h3 id="4设置ip"><a class="markdownIt-Anchor" href="#4设置ip"></a> <strong>4，设置ip</strong></h3><p><code>vim    /etc/sysconfig/network-scripts/ifcfg-ens33</code></p><p>修改：</p><p><code>BOOTPROTO=static</code></p><p><code>ONBOOT=yes</code></p><p>添加</p><p><code>IPADDR=192.168.1.102</code></p><p><code>GATEWAY=192.168.1.2</code></p><p><code>DNS1=192.168.1.2</code></p><p><code>DNS2=114.114.114.114</code></p><h3 id="5设置映射"><a class="markdownIt-Anchor" href="#5设置映射"></a> <strong>5，设置映射</strong></h3><p><code>vim /etc/hosts</code></p><p><code>192.168.1.102 hadoop102</code></p><p><code>192.168.1.103 hadoop103</code></p><p><code>192.168.1.104 hadoop104</code></p><h3 id="6创建文件夹并修改权限"><a class="markdownIt-Anchor" href="#6创建文件夹并修改权限"></a> <strong>6，创建文件夹，并修改权限</strong></h3><p><code>mkdir /opt/software</code></p><p><code>mkdir /opt/module</code></p><p><code>chown atguigu:atguigu /opt/software</code></p><p><code>chown atguigu:atguigu /opt/module</code></p><h3 id="7设置sudo权限为免密"><a class="markdownIt-Anchor" href="#7设置sudo权限为免密"></a> <strong>7，设置sudo权限为免密：</strong></h3><p><code>atguigu ALL=(ALL) NOPASSWD: ALL</code></p><h3 id="-复制虚拟机-"><a class="markdownIt-Anchor" href="#-复制虚拟机-"></a> -------复制虚拟机-------</h3><h3 id="8修改ip以及hostname"><a class="markdownIt-Anchor" href="#8修改ip以及hostname"></a> <strong>8，修改ip以及hostname</strong></h3><p>修改ip：</p><p><code>vim /etc/sysconfig/network-scripts/ifcfg-ens33</code></p><p><code>IPADDR=192.168.1.103</code></p><p><code>IPADDR=192.168.1.104</code></p><p>修改hostname：</p><p><code>hostnamectl --static set-hostname hadoop103</code></p><p><code>hostnamectl --static set-hostname hadoop104</code></p><h3 id="9所有root以及atguigu都要设置ssh免密"><a class="markdownIt-Anchor" href="#9所有root以及atguigu都要设置ssh免密"></a> 9，<strong>所有root以及atguigu都要设置ssh免密</strong></h3><p><code>ssh-keygen</code></p><p>root用户:</p><p><code>ssh-copy-id root@hadoop102</code></p><p>atguigu用户：</p><p><code>ssh-copy-id atguigu@hadoop102</code></p><h3 id="10安装vim"><a class="markdownIt-Anchor" href="#10安装vim"></a> <strong>10，安装vim</strong></h3><h3 id="11设置命令行界面设置为3"><a class="markdownIt-Anchor" href="#11设置命令行界面设置为3"></a> <strong>11，设置命令行界面（设置为3）</strong></h3><p><code>systemctl get-default         //获取当前的启动项</code></p><p><code>systemctl set-default multi-user.target</code></p><h3 id="12设置分发脚本"><a class="markdownIt-Anchor" href="#12设置分发脚本"></a> <strong>12，设置分发脚本</strong></h3><p>12.1，安装rsync</p><p><code>sudo yum install -y rsync</code><br />12.2，xsync脚本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">#! &#x2F;bin&#x2F;bash</span><br><span class="line">#1、判断是否传入待同步的文件&#x2F;目录</span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">echo &quot;必须传入一个文件&#x2F;目录&quot;</span><br><span class="line">exit</span><br><span class="line">fi</span><br><span class="line">#2、遍历待同步的多个文件&#x2F;目录</span><br><span class="line">for fileOrDir in $@</span><br><span class="line">do</span><br><span class="line">#3、判断当前待同步的文件&#x2F;目录是否存在</span><br><span class="line">#-d: 判断是否为目录</span><br><span class="line">#-f: 判断是否为文件</span><br><span class="line">#-e: 判断是否存在</span><br><span class="line">if [ -e $fileOrDir ]</span><br><span class="line">then</span><br><span class="line">#4、获取待同步的文件&#x2F;目录的父目录、文件名&#x2F;最后一个目录名</span><br><span class="line">pdir&#x3D;$(cd $(dirname $fileOrDir);pwd)</span><br><span class="line">fname&#x3D;$(basename $fileOrDir)</span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;$host&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;</span><br><span class="line">#5、在其他机器上创建父目录</span><br><span class="line">ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">#6、同步文件&#x2F;目录</span><br><span class="line">rsync -av $pdir&#x2F;$fname $host:$pdir</span><br><span class="line">done</span><br><span class="line">fi</span><br><span class="line">done</span><br><span class="line"># cd &#x2F;opt&#x2F;module&#x2F;xx</span><br><span class="line">#xsync a.txt &#x2F;opt&#x2F;module&#x2F;xx&#x2F;b.txt</span><br></pre></td></tr></table></figure><p>-av 打印进度</p><p><strong>12.3，在home家目录下创建一个bin目录并编写脚本（平时用于分发atguigu账号下的文件，如：module或者software文件夹下的）</strong></p><p><code>cd ~</code></p><p><code>mkdir bin</code></p><p><code>vim xsync</code></p><p><code>chmod +x xsync</code><br /><strong>12.4，将文件复制一份到root用户的/bin目录下（平时用于分发root账号下的文件，如：/etc/profile.d/my_env.sh）</strong></p><p><code>sudo cp /home/atguigu/bin/xsync /bin/</code></p><h3 id="13安装lrzsz用于传输文件"><a class="markdownIt-Anchor" href="#13安装lrzsz用于传输文件"></a> <strong>13，安装lrzsz，用于传输文件</strong></h3><p><code>sudo yum install lrzsz</code><br /><strong>使用rz命令上传文件，sz 文件名 命令下载文件</strong></p><h1 id="安装jdk"><a class="markdownIt-Anchor" href="#安装jdk"></a> <strong>安装JDK</strong></h1><h3 id="1检查linux中是否存在jdk如果存在就将其移除"><a class="markdownIt-Anchor" href="#1检查linux中是否存在jdk如果存在就将其移除"></a> <strong>1，检查Linux中是否存在jdk，如果存在就将其移除</strong></h3><p><code>sudo rpm -qa | grep -i java | xargs -n1sudo rpm -e --nodeps</code></p><h3 id="2将文件上传至software文件夹并解压至module文件夹并改名为java"><a class="markdownIt-Anchor" href="#2将文件上传至software文件夹并解压至module文件夹并改名为java"></a> <strong>2，将文件上传至software文件夹，并解压至module文件夹，并改名为java</strong></h3><p><code>tar -zxvf /opt/software/jdk-8u212-linux-x64.tar.gz  /opt/module/</code></p><p><code>mv /opt/module/jdk1.8.0_212 java</code></p><h3 id="3设置环境变量"><a class="markdownIt-Anchor" href="#3设置环境变量"></a> <strong>3，设置环境变量</strong></h3><p><code>export JAVA_HOME=/opt/module/java</code></p><p><code>export PATH=$PATH:$JAVA_HOME/bin</code></p><h3 id="4分发java文件"><a class="markdownIt-Anchor" href="#4分发java文件"></a> <strong>4，分发java文件</strong></h3><p><code>xsync /opt/module/java/</code></p><h3 id="5分发全局配置文件"><a class="markdownIt-Anchor" href="#5分发全局配置文件"></a> <strong>5，分发全局配置文件</strong></h3><p><code>sudo xsync /etc/profile.d/my_env.sh</code></p><p>注意：source 一下</p><p><code>source /etc/profile.d/my_env.sh</code></p><p>注意：不要在root用户连接的情况下，使用sudo去连接atguigu用户然后再进行操作atguigu这个用户</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Kafka总结</title>
      <link href="posts/56e0b1a5/"/>
      <url>posts/56e0b1a5/</url>
      
        <content type="html"><![CDATA[<h1 id="一-kafka概述"><a class="markdownIt-Anchor" href="#一-kafka概述"></a> 一、kafka概述</h1><h2 id="1-什么是kafka"><a class="markdownIt-Anchor" href="#1-什么是kafka"></a> 1、什么是kafka?</h2><p>​kafka是分布式的基于发布/订阅[一个生产者多个消费者]的消息队列</p><h2 id="2-kafka应用场景"><a class="markdownIt-Anchor" href="#2-kafka应用场景"></a> 2、kafka应用场景:</h2><p>​kafka主要用于实时场景。kafka有时候也会结合flume使用,此时kafka作为flume与flume之间的缓冲区</p><h2 id="3-kafka基础架构"><a class="markdownIt-Anchor" href="#3-kafka基础架构"></a> 3、kafka基础架构</h2><p>​<code>producer:</code> 生产者,向topic写消息<br />​<code>topic:</code>主题,在工作中一般是一个业务一个主题<br />​<code>partition:</code> topic为了实现分布式的存储以及提高生产/消费的吞吐量,将topic划分为多个分区,每个分区保存在不同的节点上<br />​<code>broker:</code> kafka的一个节点<br />​<code>consumer:</code> 消费者,向topic中拉取消息<br />​<code>consumer group:</code>消费者组,因为一个topic有多个分区,如果只有一个消费者,此时是串行消息,所以为了调高消费的速度,引出了消费者组的概念,此时一个消费者组消费一个topic。消费者组中有多个消费者,这多个消费者消费topic不同分区的数据。一个分区只能被一个消费者组中的一个消费者所消费<br />​<code>partition:</code> 因为保存在broker上，所以如果broker宕机,分区数据消失,所以为了保证分区数据的安全性,对每个分区提供了副本机制<br />​<code>leader:</code> 副本中的一个角色,produer写入数据以及消费者消费数据都找分区的leader<br />​<code>follower:</code> 副本中的一个角色,follower同步leader的数据,如果leader宕机,会选举出一个新leader<br />​<code>zookeeper:</code> broker上下线以及leader选举都依赖zookeeper<br />​<code>offset:</code>数据的偏移量,也相当于是数据唯一标识。消费者消费数据的时候会进行记录,记录下一次应该从哪个offset开始消费</p><h1 id="2-kafka常用指令"><a class="markdownIt-Anchor" href="#2-kafka常用指令"></a> 2、kafka常用指令</h1><h2 id="1-topic相关"><a class="markdownIt-Anchor" href="#1-topic相关"></a> 1、topic相关:</h2><p>​1、创建topic:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --topic topic名称 --bootstrap-server broker主机:9092,.. --partitions 分区数 --replication-factor 副本数</span><br></pre></td></tr></table></figure><p>​2、查看kafka集群所有topic：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --list --bootstrap-server broker主机:9092,..</span><br></pre></td></tr></table></figure><p>​3、查看某个topic详细信息:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --describe --topic topic名称 --bootstrap-server broker主机:9092,..</span><br></pre></td></tr></table></figure><p>​4、修改topic[只能修改分区数,而且是只能增加分区不能减少分区]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --alter --topic topic名称 --bootstrap-server broker主机:9092,.. --partitions 分区数</span><br></pre></td></tr></table></figure><p>​5、删除topic:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --delete --topic topic名称 --bootstrap-server broker主机:9092,..</span><br></pre></td></tr></table></figure><h2 id="2-生产者"><a class="markdownIt-Anchor" href="#2-生产者"></a> 2、生产者:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-producer.sh --topic topic名称 --broker-list broker主机:9092,..</span><br></pre></td></tr></table></figure><h2 id="3-消费者"><a class="markdownIt-Anchor" href="#3-消费者"></a> 3、消费者:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-consumer.sh --topic topic名称 --bootstrap-server broker主机:9092 [--from-beginning --group 消费者组名称]</span><br></pre></td></tr></table></figure><h2 id="4-查看分区数据"><a class="markdownIt-Anchor" href="#4-查看分区数据"></a> 4、查看分区数据:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-dump-log.sh --files 数据文件路径 --print-data-log</span><br></pre></td></tr></table></figure><h2 id="5-查看消费者组消费到topic哪个offset"><a class="markdownIt-Anchor" href="#5-查看消费者组消费到topic哪个offset"></a> 5、查看消费者组消费到topic哪个offset：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-consumer-group.sh --all-groups --all-topics --describe --bootstrap-server 主机:9092</span><br></pre></td></tr></table></figure><h1 id="3-kafka原理"><a class="markdownIt-Anchor" href="#3-kafka原理"></a> 3、kafka原理</h1><p>​1、kafka工作流程: 与上面的基础架构一致<br />​2、kafka数据存储机制：</p><blockquote><p>​Topic: 是逻辑上的概念<br />​partition: 物理上真实存在,以目录的形式存在<br />​segment: 相当于是partition的一个分段<br />​log: 数据存储文件<br />​index: log文件数据的索引文件<br />​timestampindex: log文件数据的时间索引文件</p></blockquote><p>​<code>partition为什么需要切分成多个segment？</code><br />​partition如果只有一个数据文件和索引文件,那么随着时间的增加,数据文件越来越大,索引文件也越来越大,此时查找数据会越来越慢。所以切分成多个segment能够提高查询效率<br />​<code>segment文件的命名规则:</code><br />​每个partition第一个segment文件名为00000000000000000000<br />​后续第N个segment文件名 = 第 N -1 个segment最后一个offset+1<br />​    根据segment命名规则,后续查找offset对应的数据的时候,可以根据segment文件名用二分查找法可以很快确定offset数据处于哪个segment<br />​<code>如果根据offset找到数据?</code><br />​1、根据segment文件名用二分查找法确定offset处于哪个segment<br />​2、再根据segment的index文件确定offset处于log文件哪个区间<br />​3、扫描log文件对应的区间获取数据</p><h1 id="4-生产者"><a class="markdownIt-Anchor" href="#4-生产者"></a> 4、生产者</h1><h2 id="1-分区策略确定数据写到哪个分区"><a class="markdownIt-Anchor" href="#1-分区策略确定数据写到哪个分区"></a> 1、分区策略[确定数据写到哪个分区]:</h2><p>​1、直接指定分区号: 数据直接发到指定的分区<br />​2、如果没有指定分区号,但是有key: 数据发到 key.hashCode % 分区数 分区<br />​3、没有分区号,也没有指定key:</p><ul><li><p>​新版本：</p><p>1、第一个批次发送的时候会生成一个随机数, 数据发到 随机数%分区数 分区<br />​2、第N个批次发送的时候,会排除掉 N-1 次发送的分区,从剩余的分区中随机选择一个</p></li><li><p>​旧版本:</p><p>1、第一个批次发送的时候会生成一个随机数, 数据发到 随机数%分区数 分区</p><p>2、第N个批次发送的时候,会将数据发到 (第一个批次生成的随机数+ (N-1))%分区数 分区</p></li></ul><h2 id="2-数据可靠性生成发送的消息是否真实到达kafka"><a class="markdownIt-Anchor" href="#2-数据可靠性生成发送的消息是否真实到达kafka"></a> 2、数据可靠性[生成发送的消息是否真实到达kafka]:</h2><p>通过ack机制[确定消息机制]可以确保数据的可靠性</p><ul><li><p>ack=0: leader接收到消息之后立即返回确认消息给生产者,此时数据还没有落盘<br />存在问题: 如果leader返回了确认消息之后宕机,此时数据因为还没有落盘,所以数据丢失</p></li><li><p>ack=1：  leader接收到消息并且落盘之后才会返回确认消息给生产者<br />存在问题:   leader接收到消息并且落盘之后返回确认消息给生产者,返回消息之后宕机了,此时会从follower选举出新leader,新leader中没有该数据,所以也出现了数据丢失</p></li><li><p>ack=-1：leader接收到消息并且落盘并且所有的follower全部同步完数据之后才会返回确认消息给生产者<br />存在问题:   leader接收到消息并且落盘并且所有的follower全部同步完数据,在返回消息之前leader宕机,选举出新leader,因为之前的leader宕机了没有返回确认消息给生产者，所以生产者认为kafka没有接受到消息,此时生产者会重新发送消息给leader,对于新leader来说有两个相同的数据,数据重复。</p></li></ul><p><strong>ack=-1的时候要求所有的follower都同步完消息之后才会返回确认消息,所以此时如果某一个follower因为网络故障导致同步迟迟完成不了,此时会将该follower踢出ISR列表</strong><br />ISR: 与leader同步到了一定程度[当前副本的LEO&gt;=分区HW]的副本集合<br />LEO: 每个副本最后一个offset<br />HW: 所有副本中最小的LEO</p><blockquote><p>故障处理机制:<br /><code>follower故障:</code> follower故障解决之后,应该会清除掉故障之前HW之后的所有数据,重新从leader同步数据<br /><code>leader故障:</code> 首先从ISR列表中选择一个作为新leader,其余follower需要清除掉HW之后的所有数据重新从新leader同步数据</p></blockquote><h2 id="3-exactly-once"><a class="markdownIt-Anchor" href="#3-exactly-once"></a> 3、exactly once</h2><blockquote><p>​三种容错语义:<br />​at-lest-once: 数据最少一条[数据重复]<br />​at-most-once: 数据最多一条[数据丢失]<br />​exactly-once: 数据有且仅有一条</p></blockquote><p>kafka如何确保exactly once:  通过 ack=-1 + 幂等性 [前提: 生产者不宕机,因为producerid是在生产者启动的时候生成的所以如果producer宕机重启会重新生成一个新的producerid]<br />kafka确保exactly once借鉴的是mysql的主键思想:<br />​kafka每次发送数据的时候都会带上一个主键[ producerid+parititionid+sequceNumber],broker会缓存该主键,所以后续每个发送数据的时候都会判断当前数据主键在缓存中是否存在,如果存在代表该数据之前已经发送过,当前数据标记无效,如果不存在代表数据没有发送过,正常写入log文件<br />​producerid: 生产者的唯一标识,是生产者在启动的时候生成的<br />​partitionid：分区号<br />​sequceNumber: 发到分区的第几条数据</p><h1 id="5-消费者"><a class="markdownIt-Anchor" href="#5-消费者"></a> 5、消费者</h1><h2 id="1-消费组消费数据的方式-采用主动拉取数据的方式"><a class="markdownIt-Anchor" href="#1-消费组消费数据的方式-采用主动拉取数据的方式"></a> 1、消费组消费数据的方式: 采用主动拉取数据的方式</h2><h2 id="2-分区分配策略消费者组中的消费者究竟消费哪个分区的数据"><a class="markdownIt-Anchor" href="#2-分区分配策略消费者组中的消费者究竟消费哪个分区的数据"></a> 2、分区分配策略[消费者组中的消费者究竟消费哪个分区的数据]</h2><p>​1、轮询<br />​比如: Topic[partition0、partition1、partition2、partition3、partition4]<br />​  consumer group[consumer1,consumer2]<br />​此时轮询分配:<br />​consumer1: partition0、partition2、partition4<br />​consumer2: partition1、partition3、<br />​2、range<br />​1、评估每个消费者大概消费几个分区的数据: 分区数/消费者个数<br />​2、确定前几个消费者多消费1一个分区的数据: 分区数%消费者个数<br />​比如: Topic[partition0、partition1、partition2、partition3、partition4]<br />​  consumer group[consumer1,consumer2]<br />​此时分区分配:<br />​1、评估每个消费者大概消费几个分区的数据: 5/2 = 2<br />​2、确定前几个消费者多消费1一个分区的数据: 5%2 = 1<br />​consumer1: partition0、partition1、partition2<br />​consumer2: partition3、partition4</p><h2 id="3-offset维护指消费者组下一次应该从哪里开始消费"><a class="markdownIt-Anchor" href="#3-offset维护指消费者组下一次应该从哪里开始消费"></a> 3、offset维护[指消费者组下一次应该从哪里开始消费]</h2><p>​0.9版本之后offset一直维护在kafka内部topic[__consumer_offset]中</p><h1 id="6-高效读写数据"><a class="markdownIt-Anchor" href="#6-高效读写数据"></a> 6、高效读写数据</h1><p>​1、分区: 提高并行度<br />​2、顺序写磁盘： 减少磁头寻址的时间[因为每个分区的数据都在一块,所以磁头寻址只需要一次就够了]<br />​3、pagecahe<br />​pagecache是每个broker都有的一个内存区域,后续生产者写数据的时候首先是写入pagecache中<br />​1、减少与磁盘的交互次数[在pagecache中可以累积多个批次的数据之后再统一写入磁盘]<br />​2、减少磁头寻址的时间[每个批次的数据在pagecache中会进行物理地址的排序,后续写入的时候磁头可以一次扫过]<br />​3、如果网络够好,生产者生产数据的速度=消费者消费数据的速度,此时消费者可以直接从pagecache中获取数据,不用经过磁盘<br />​4、pagecache不在JVM中,不会增加GC的负担<br />​4、零拷贝<br />​系统内存分为内核区和用户区<br />​正常流程:<br />​1、通过io流读取数据到内核区的pagecache中<br />​2、将数据从内核区拷贝到用户区,从而对数据进行操作<br />​3、将数据从用户区拷贝到内核区的socket缓冲区<br />​4、将数据从socket缓冲区拷贝到网卡<br />​零拷贝:<br />​1、通过io流读取数据到内核区的pagecache中<br />​2、将数据从pagecache拷贝到网卡</p><h1 id="7-zookeeper在kafka中作用"><a class="markdownIt-Anchor" href="#7-zookeeper在kafka中作用"></a> 7、zookeeper在kafka中作用</h1><p>​broker在启动的时候会选举出一个controller，后续controller会监控broker上下线以及leader的选举[此时都需要依赖zookeeper]<br />​leader选举流程<br />​1、broker启动的时候选举出一个conroller，同时会在zookeeper[/brokers/ids/]注册<br />​2、broker中存储的有很多分区,随着broker启动,分区也会在zookeeper[/brokers/topics/topic名称/partitions/分区号/state]上注册<br />​3、如果broker宕机,/brokers/ids下面该broker节点消息,conroller会一直监听/brokers/ids目录，所以能够立即知道broker宕机了<br />​4、conroller会从/brokers/topics/topic名称/partitions/分区号/state获取所有的分区的状态,根据宕机的broker进行筛选哪些分区leader消失<br />​5、conroller会从ISR列表中选举出一个新leader[采用随机但是需要考虑leader的负载均衡]<br />​6、conroller会更新/brokers/topics/topic名称/partitions/分区号/state</p><h1 id="8-kafka事务"><a class="markdownIt-Anchor" href="#8-kafka事务"></a> 8、kafka事务</h1><p>​kafka事务一般是指producer事务。<br />​producer事务:<br />​数据要想保证在kafka中的exactly once,必须ack=-1 &amp;&amp; 开启幂等性。<br />​在生产者发送数据的时候,<a href="http://xn--transaction-km8q8qjb39tezap42a09yui2g6l8b.id">会在代码中写死一个transaction.id</a>,producer会将producer.id与transaction.id进行绑定,将其保存到kafka内部topic[__transaction_state]中同时还会将事务的状态也保存到__transaction_state。<br />​后续如果producer宕机，producer重启之后会首先查看__transaction_state中上一次的事务状态,如果事务的状态是未提交,那么会回滚上一次的事务，重新发送数据。同时根据transaction.id获取producerid,将其与分区号、sequceNumber组合作为数据的主键。<br />​consumer事务[精准消费一次]: kafka消费者消费数据采用主动拉取的方式,所以kafka不能保证消费者精准一次消费<br />4、producer消息发送流程<br />​1、在main方法中创建producer客户端<br />​2、封装数据成ProducerRecord对象，通过send方法发送数据<br />​3、在send方法中会对数据经过拦截器处理、序列化器进行序列化、分区器确定数据写到哪个分区<br />​4、将该条数据发到共享变量Accumulator[就是相当于是Map,Map的key=topic名称+分区号,Map的value就是发到该分区的一个批次的数据]中,等到一个topic一个分区的数据达到一个批次之后,sender线程会将数据发到broker的topic分区中</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
